{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_Data Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tauseef1234/Deep_Learning/blob/main/CNN_Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Cats and Dogs - Data Augmentation with Tensorflow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0pdCY3NENwe"
      },
      "source": [
        "In this notebook, a CNN on the FULL Cats-v-dogs dataset will be trained on a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn-6c02VmqiN"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd5zTNk_Ef0P"
      },
      "source": [
        "This codeblock downloads the complete cats-v-dogs dataset in a zip file and then unzips the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sd9dQWa23aj",
        "outputId": "304522d9-667a-447d-c036-32f823541b79"
      },
      "source": [
        "# This code block downloads the full Cats-v-Dogs dataset and stores it as \n",
        "# cats-and-dogs.zip. It then unzips it to /tmp\n",
        "# which will create a tmp/PetImages directory containing subdirectories\n",
        "# called 'Cat' and 'Dog' (that's how the original researchers structured it)\n",
        "# If the URL doesn't work, \n",
        "# .   visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "# And right click on the 'Download Manually' link to get a new URL\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-30 17:50:40--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.206.124.109, 2600:1407:d800:18f::e59, 2600:1407:d800:19a::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.206.124.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.68M  62.2MB/s    in 12s     \n",
            "\n",
            "2021-09-30 17:50:52 (65.6 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi3yD62a6X3S",
        "outputId": "2cc62aff-352b-4f6e-a5c2-94f0a5b1c04d"
      },
      "source": [
        "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(len(os.listdir('/tmp/PetImages/Dog/')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12501\n",
            "12501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-QkLjxpmyK2"
      },
      "source": [
        "# Use os.mkdir to create your directories\n",
        "# You will need a directory for cats-v-dogs, and subdirectories for training\n",
        "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n",
        "try:\n",
        "    #YOUR CODE GOES HERE\n",
        "    os.mkdir(\"/tmp/cats-v-dogs\")\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/training/cats\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/training/dogs\")\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvSODo0f9LaU",
        "outputId": "43e885d6-b01a-4f93-995d-a06928c2d8f2"
      },
      "source": [
        "# Write a python function called split_data which takes\n",
        "# a SOURCE directory containing the files\n",
        "# a TRAINING directory that a portion of the files will be copied to\n",
        "# a TESTING directory that a portion of the files will be copie to\n",
        "# a SPLIT SIZE to determine the portion\n",
        "# The files should also be randomized, so that the training set is a random\n",
        "# X% of the files, and the test set is the remaining files\n",
        "# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n",
        "# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n",
        "# and 10% of the images will be copied to the TESTING dir\n",
        "# Also -- All images should be checked, and if they have a zero file length,\n",
        "# they will not be copied over\n",
        "#\n",
        "# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n",
        "# os.path.getsize(PATH) gives you the size of the file\n",
        "# copyfile(source, destination) copies a file from source to destination\n",
        "# random.sample(list, len(list)) shuffles a list\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "# YOUR CODE STARTS HERE\n",
        "    all_files = []\n",
        "    for file_name in os.listdir(SOURCE):\n",
        "      if os.path.getsize(SOURCE+file_name)>0:\n",
        "        all_files.append(file_name)\n",
        "      else:\n",
        "        print (f'{file_name} is zero length, so ignoring')\n",
        "\n",
        "    len_files = len(all_files)\n",
        "    split = int(SPLIT_SIZE*len_files)\n",
        "    shuffle_files = random.sample(all_files,len_files)\n",
        "    x_train = shuffle_files[:split]\n",
        "    x_test = shuffle_files[split:]\n",
        "    \n",
        "    for file_name in x_train:\n",
        "      copyfile(SOURCE+file_name,TRAINING+file_name)\n",
        "    for file_name in x_test:\n",
        "      copyfile(SOURCE+file_name,TESTING+file_name)\n",
        "# YOUR CODE ENDS HERE\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Expected output\n",
        "# 666.jpg is zero length, so ignoring\n",
        "# 11702.jpg is zero length, so ignoring"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666.jpg is zero length, so ignoring\n",
            "11702.jpg is zero length, so ignoring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zezu4-e7JoZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8849be0a-40bd-488d-ba4b-339e4770520f"
      },
      "source": [
        "os.path.getsize('/tmp/PetImages/Dog/11702.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luthalB76ufC",
        "outputId": "aaa4e4d9-f888-4b1f-84e8-1ed218de6de3"
      },
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
        "\n",
        "# Expected output:\n",
        "# 11250\n",
        "# 11250\n",
        "# 1250\n",
        "# 1250"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11250\n",
            "11250\n",
            "1250\n",
            "1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BQrav4anTmj",
        "outputId": "4b51dfca-61b0-43a8-b216-c2e2c043b73f"
      },
      "source": [
        "# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "# USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "model = tf.keras.models.Sequential([\n",
        "# YOUR CODE HERE\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2), \n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Flatten(), \n",
        "        tf.keras.layers.Dense(512, activation='relu'), \n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  \n",
        "])\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlNjoJ5D61N6",
        "outputId": "8d707831-2aea-4aa0-a232-70cf765db340"
      },
      "source": [
        "TRAINING_DIR = '/tmp/cats-v-dogs/training'#YOUR CODE HERE\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   fill_mode = 'nearest')#YOUR CODE HERE\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                        TRAINING_DIR, \n",
        "                        target_size = (150,150),\n",
        "                        batch_size = 20,\n",
        "                        class_mode = 'binary')#YOUR CODE HERE\n",
        "\n",
        "VALIDATION_DIR = '/tmp/cats-v-dogs/testing'#YOUR CODE HERE\n",
        "validation_datagen = ImageDataGenerator( rescale = 1.0/255.)#YOUR CODE HERE\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "                        VALIDATION_DIR, \n",
        "                        target_size = (150,150),\n",
        "                        batch_size = 10,\n",
        "                        class_mode = 'binary')#YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "# Expected Output:\n",
        "# Found 22498 images belonging to 2 classes.\n",
        "# Found 2500 images belonging to 2 classes."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22498 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyS4n53w7DxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171c1984-d369-41f8-e1a6-7eee887bcd96"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                              epochs=5,\n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator)\n",
        "\n",
        "# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation\n",
        "# i.e. acc:A1 and val_acc:A2 will be visible, and both A1 and A2 will be > .9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 629/1125 [===============>..............] - ETA: 1:30 - loss: 0.6769 - accuracy: 0.6040"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1125/1125 [==============================] - 245s 189ms/step - loss: 0.6498 - accuracy: 0.6316 - val_loss: 0.5708 - val_accuracy: 0.7180\n",
            "Epoch 2/5\n",
            "1125/1125 [==============================] - 218s 194ms/step - loss: 0.5841 - accuracy: 0.6954 - val_loss: 0.4858 - val_accuracy: 0.7692\n",
            "Epoch 3/5\n",
            "1125/1125 [==============================] - 223s 198ms/step - loss: 0.5574 - accuracy: 0.7209 - val_loss: 0.4601 - val_accuracy: 0.7908\n",
            "Epoch 4/5\n",
            "1125/1125 [==============================] - 212s 188ms/step - loss: 0.5404 - accuracy: 0.7320 - val_loss: 0.5100 - val_accuracy: 0.7764\n",
            "Epoch 5/5\n",
            "1125/1125 [==============================] - 213s 189ms/step - loss: 0.5219 - accuracy: 0.7493 - val_loss: 0.4431 - val_accuracy: 0.8044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWZrJN4-65RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "755f44d6-f8be-4ae8-8b80-e99876971040"
      },
      "source": [
        "# PLOT LOSS AND ACCURACY\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "# Desired output. Charts with training and validation metrics. No crash :)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAEICAYAAADFgFTtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeGElEQVR4nO3deZhkVZ3m8fetfd+LragiKQS0SsWGEoVWRFBZBXEZQYQGtZmRccCZ0Z7udmm01XEcW3wYu8UNQVFEFGkGxOlWNnEBqoCSLhYFCoad2ndKqvLXf5wT5snIiMjIJDMiK/P7eZ544sa95977i5sZ+eY5NyKuI0IAACAZ1e4CAAAYSghGAAAKBCMAAAWCEQCAAsEIAECBYAQAoEAwAr2wfYPtvxjotu1k+1HbbxqE7Ybtl+Tpi21/opm2/djP6bb/pb91Ao2YzzFiOLK9uXg4SdJ2STvz4/8YEd9rfVVDh+1HJX0gIn4+wNsNSftHxEMD1dZ2h6SVksZGxI6BqBNoZEy7CwAGQ0RMqUw3CgHbY/hji6GC38ehgaFUjCi2j7T9hO3/YfsZSd+2PdP2dbZX2V6Xp/cu1rnZ9gfy9Fm2b7P9xdx2pe3j+tl2X9u32t5k++e2/9H25XXqbqbGv7f9q7y9f7E9p1h+hu3HbK+x/bEGx+c1tp+xPbqYd4rt3+XpQ23/xvZ620/b/ortcXW2dantzxSPP5rXecr2+6ranmD7btsbbT9u+4Ji8a35fr3tzbYPqxzbYv3Dbd9pe0O+P7zZY9PH4zzL9rfzc1hn+5pi2cm278nP4WHbx+b53YatbV9Q+Tnb7shDyu+3/f8l3ZjnX5V/Dhvy78jiYv2Jtv8h/zw35N+xibavt/1fqp7P72yfUuu5oj6CESPRHpJmSdpH0jlKr4Nv58cLJG2T9JUG679G0oOS5kj6gqRv2XY/2n5f0h2SZku6QNIZDfbZTI3vkXS2pN0kjZP0EUmyvUjSV/P298r721s1RMTtkrZIOqpqu9/P0zsl/df8fA6TdLSkcxvUrVzDsbmeN0vaX1L1+c0tks6UNEPSCZI+aPttedkR+X5GREyJiN9UbXuWpOslXZSf25ckXW97dtVz6HFsaujtOH9XaWh+cd7WhbmGQyV9R9JH83M4QtKj9Y5HDW+Q9DJJx+THNygdp90k3SWpHPr/oqRDJB2u9Hv8V5I6JV0m6b2VRrYPkjRP6digLyKCG7dhfVP6A/WmPH2kpD9KmtCg/askrSse36w0FCtJZ0l6qFg2SVJI2qMvbZX+6O6QNKlYfrmky5t8TrVq/Hjx+FxJP8vTn5T0g2LZ5HwM3lRn25+RdEmenqoUWvvUafthST8pHoekl+TpSyV9Jk9fIunzRbsDyrY1tvtlSRfm6Y7cdkyx/CxJt+XpMyTdUbX+bySd1dux6ctxlrSnUgDNrNHua5V6G/3+5ccXVH7OxXNb2KCGGbnNdKXg3ibpoBrtJkhap3TeVkoB+k+tfr0Nhxs9RoxEqyLi+coD25Nsfy0PTW1UGrqbUQ4nVnmmMhERW/PklD623UvS2mKeJD1er+Ama3ymmN5a1LRXue2I2CJpTb19KfUO3257vKS3S7orIh7LdRyQhxefyXV8Tqn32JtuNUh6rOr5vcb2TXkIc4Ok/9Tkdivbfqxq3mNKvaWKesemm16O83yln9m6GqvOl/Rwk/XW8qdjY3u07c/n4diN6up5zsm3CbX2lX+nr5T0XtujJJ2m1MNFHxGMGImq34r93yUdKOk1ETFNXUN39YZHB8LTkmbZnlTMm9+g/Yup8ely23mfs+s1joj7lILlOHUfRpXSkOwDSr2SaZL+tj81KPWYS9+XdK2k+RExXdLFxXZ7e+v8U0pDn6UFkp5soq5qjY7z40o/sxk11ntc0n51trlFabSgYo8abcrn+B5JJysNN09X6lVWalgt6fkG+7pM0ulKQ9xbo2rYGc0hGIE0XLhN6c0dsyT93WDvMPfAlkq6wPY424dJeusg1fgjSSfafl1+o8yn1ftr//uSzlcKhquq6tgoabPtl0r6YJM1/FDSWbYX5WCurn+qUm/s+Xy+7j3FslVKQ5gL62z7p5IOsP0e22Nsv1vSIknXNVlbdR01j3NEPK107u+f8pt0xtquBOe3JJ1t+2jbo2zPy8dHku6RdGpuv0TSO5uoYbtSr36SUq+8UkOn0rD0l2zvlXuXh+XevXIQdkr6B9Fb7DeCEUjnsyYq/Tf+W0k/a9F+T1d6A8sapfN6Vyr9Qayl3zVGxApJ/1kp7J5WOg/1RC+rXaH0hpAbI2J1Mf8jSqG1SdI3cs3N1HBDfg43Snoo35fOlfRp25uUzon+sFh3q6TPSvqV07thX1u17TWSTlTq7a1RejPKiVV1N6u343yGpBeUes3PKZ1jVUTcofTmngslbZB0i7p6sZ9Q6uGtk/Qpde+B1/IdpR77k5Luy3WUPiLpXkl3Slor6X+p+9/y70h6hdI5a/QDH/AHhgjbV0p6ICIGvceK4cv2mZLOiYjXtbuWXRU9RqBNbL/a9n556O1YpfNK1/S2HlBPHqY+V9LX213LroxgBNpnD6WPEmxW+gzeByPi7rZWhF2W7WOUzsc+q96Ha9EAQ6kAABToMQIAUOBLxIeBOXPmREdHR7vLAIBdyrJly1ZHxNzq+QTjMNDR0aGlS5e2uwwA2KXYrv7GJEkMpQIA0A3BCABAgWAEAKBAMAIAUCAYAQAoNAzGfH20Y6rmfdj2Vxusc3P+BnnZ/mmtS7TYvsB2vStoV9q8LV95vPL407arr/rdb7a/bPvJfN0yAAAk9d5jvELSqVXzTs3zexURx0fE+v4UJultSpeOqWzrkxHx835uq5schqcoXUPtDQOxzTr74eMwALCL6S0YfyTphHwNN9nuULpa9i9tf9X2UtsrbH+q1sq2H7U9J09/zPbvbd+mdCHQSpu/tH2n7eW2f5yvoH24pJMk/W/b9+QvWr7U9jvzOkfbvtv2vbYvqVyLLO/vU7bvysteWqMsSTpS0gqli66eVtSyu+2f5FqW5zpk+0zbv8vzvpvn/ame/Hhzvj/S9i9tX6t0yRjZvsb2snyszinWOTbXutz2L/KXSf/B9ty8fJTthyqPAQCDr2EwRsRaSXcoXclbSr3FH0b6gtWPRcQSSa+U9Abbr6y3HduH5HVfJel4Sa8uFl8dEa+OiIMk3S/p/RHxa6WreX80Il4VEQ8X25og6VJJ746IVyh9SUF5sdTVEXGwUujVG649TanX+xOl4B+b518k6ZZcy8GSVtheLOnjko7K88+v9zwLB0s6PyIOyI/fFxGHSFoi6Tzbs3PYfUPSO/J235UvQnq50nX6pHQF7+URsap6B7bPyf+YLF21qsdiAEA/NXN+rRxOLYdR/4PtuyTdLWmximHPGl4v6ScRsTUiNiqFXsXLcw/rXqVAWNxLPQdKWhkRv8+PL1O6ynjF1fl+maSO6pVz7/d4SdfkWm6XVDmPepRSoCoidkbEhjzvqspFT/M/C725IyJWFo/Ps71c6YKj8yXtL+m1km6ttCu2e4mkM/P0+yR9u9YOIuLrEbEkIpbMnUuHEgAGSjPnwP5Z0oW2D5Y0KSKW2d5XqTf26ohYZ/tSSRP6WcOlkt4WEcttn6U0zPliVK6AvlO1n98xkmZIute2JE2StE3SdX3czw7lfyzyOctxxbItlQnbRyr1/A6LiK22b1aDYxURj9t+1vZRkg5VV+8RANACvfYYI2KzpJuUejKV3uI0pT/+G2zvrq6h1npulfQ22xNtT5X01mLZVElP5+HMMgQ25WXVHpTUYfsl+fEZkm7p7XkUTpP0gYjoiIgOSftKenO+wOcvlIdlbY+2PV3SjZLeZXt2nj8rb+dRSYfk6ZMkjVVt0yWty6H4UqWeopR6j0fkfzLK7UrSN5WGVK+KiJ19eG4AgBep2Y8qXCHpoHyviFiuNIT6gNIFMX/VaOWIuEvSlZKWS7pB0p3F4k8oDWf+Km+v4geSPprfZLNfsa3nJZ0t6ao8/Nop6eJmnkQOv2MlXV9sb4uk25TC+nxJb8zbXSZpUUSskPRZSbfk4dAv5VW/oXRudbmkw1T0Eqv8TNIY2/dL+rxSICqfNzxH0tV5G1cW61wraYrqDKMCAAYPFyoegvLnQC+MiNc3037JkiXB1TUAoG9sL8tvIu2Gz9kNMbb/Wmk4l3OLANAGfOvLEBMRn4+IfSLitnbXAgAjEcEIAECBYAQAoEAwAgBQIBgBACgQjAAAFAhGAAAKBCMAAAWCEQCAAsEIAECBYAQAoEAwAgBQIBgBACgQjAAAFAhGAAAKBCMAAAWCEQCAAsEIAECBYAQAoEAwAgBQIBgBACgQjAAAFAhGAAAKBCMAAAWCEQCAAsEIAECBYAQAoEAwAgBQIBgBACgQjAAAFAhGAAAKY9pdAAAAktTZKW3cKK1ZI61dm+7L6ep5a9dKDz4ojR49sHUQjACAARUhbd3aM9gahdyaNdK6ddLOnfW3O2OGNGuWNHt2uu2/v7R9uzRp0sDWTzACGFA7dkibNkkbNqTpiRPTH65Jk6Rx4yS73RWiL7Zvrx1ivYXcH/9Yf5uTJ6dgq4Tc/Pld02XwldMzZkhjWpRYBCMASWkYa9OmNJS1cWMKturpWvOql2/dWn8fdgrISliWoVk978UuGzu2dcduV7BjR+qRNRtslektW+pvc9y47iF2wAHdA61WyM2aJY0f37rn3R8EI7CLi0h/vPobZpXpTZt635ctTZ0qTZsmTZ+e7mfOlDo6us+rTI8ZI23blsKy3n1lessWafXq7vMq9/0xZkzfArW/ATxx4sCf42okIv28+tJ7W7tWWr++/jZHjeoeYnvvLR10UP3eW2V60qThOQJAMAJtEiE9/3xzvbDegq2zs/f9TZ7cFVyV+3nzeoZZ9XQ5b8qU9Ee0lSrHqTpIG4Vsb8vWr5eeeqrnsu3b+1fjuHEDE7ZS78OWfTkPN2tWOg/XqPc2e3b62bb65zqUEYxAP2zf3lwvrLflO3b0vq+JE3sG1Ete0jjAqqenTm1tr2Yg2ekYTJyY/pAPpp07Uwj3J2zrLVu1qvay3n72kyf37MXVC7bK9MyZrTsPN5xxCIEqzz8vPfqo9Mgj6fbww13Tzz6bQq2ZnsW4cT0Dap99eu+hVU9zrqx1Ro9OgTR58uDv64UXUlCWodnZueuchxvOCEaMOBEp4CphV3178snu7SdPlhYulPbbT3rd63ofbqxM84cNjYwdm27TprW7ElQjGDEsbdsmrVxZP/zKN3TY6VzbfvtJb3lLCsHyNnfu8HyDAYDaCEbskiKkZ56pPdz5yCPS0093bz9lSgq5/feXjjmme/Dts480YUJ7ngeAoYdgxJC1dWv9Xt/KlT17ffPnp6A77rievb45c+j1AW31wgvpMzmbN3fdl9P9vd+4ccBPxBOMaJvOztSzqzfc+cwz3dtPnZpC7sADu8Jvv/3S/YIFnNMDXrSI9JU1fQmmZts2+iqcaqNGpWGeKVPSSf7K/axZ6T/gcn4zn1XqI4IRg2rLlsa9vuef72o7alRXr++EE3r2+mbPptcHSOr6cOeL7XXVmtfoQ5LVxoypHWC77ZZetOW8vtyPH9/WFzvBiBelszN9ULper+/ZZ7u3nzYt9fIWLZJOPLF78C1YkD7iAOxSItKHErdvT2G1fXtz07XmVb4CqJlQi2i+xvHjawfQvHm15zcbYsP0BUswolebN9cPvpUru4+QjBqVAm7hQumtb+0+3LlwYfoAMr0+DIjKp/H7Gj79Da1G0wMxnGend4HVCqY5c5rvbVXPmzyZT/33EUcL2rmzfq/v4YfTN3eUpk9PYfeKV0gnn9yz18cH0kegiNTbWbcu3davT/ebNg1eaPVlyK+R8eO7bhMm9JyeMCGd4K63vLpto+WN1hszhv8ahwiCcQR773ulO+9M3/JS9vpGj04fYVi4UDrllJ7n+mbObFvJGEyVi+hVwq2vt768uWLs2N7DZcaMwQ2i8eO5DhZqIhhHsPHj0zfoV4ff/Pn0+nZZEWnsu1ZwVXpxjW4vvFB/23YaLpg5s+s2b173x9W3qVNTCJXhNH4831iNIY1gHMG+9a12V4CaItIQZH96bevXN/526lGjUk+sDK8FCxqHW+XGJRgwQhCMwGDo7EwfPO4txOrNb3T+bPTonuG2777NhdvUqYQb0AuCEWjG+vXS/fdLTzzRXM9tw4bG71QcPbp7YM2ald7R1Gy4cV4MGDQEI1Bat0667750W7Gi6/6pp3q2HTu2e2Dttlv6Wp5mwm3yZMINGKIIRoxMa9f2DL/77uv+7eOTJkkve5l09NHS4sXpWwk6OrrCbdIkwg0YhghGDG9r1vQMvxUrun8lz+TJKQDf8pYUfpUQ3GcfzscBIxDBiOFh1araPcDnnutqM2VKCrzjjusKv8WL0+dTCEAAGcGIXUdECsBaPcDVq7vaTZ3a9WWsZQ9w/nyGPgH0imDE0BORhjpr9QDXrOlqN21aCr2TT+7eA5w3jwAE0G8EI9onIl10sTr87rsvvTmmYsaMFHhvf3v3HuBeexGAAAYcwYjBF5E+7lCrB7h+fVe7mTNT6L3rXSn4KiG4xx4EIICWIRgxcCKkJ5+s3QPcsKGr3ezZKfBOPbV7D3D33QlAAG1HMKLvIqTHH6/dA9y0qavd3Lkp8E4/vXsPcO5cAhDAkEUwor7OzhSAtXqAmzd3tdtttxR4Z57ZvQc4d277ageAfiIYkQLwscd69gDvv1/asqWr3R57pMA7++yuHuCiRenq4gAwTBCMI9mHPiT99rcpALdu7Zq/556p1/f+93f1/hYtSl90DQDDHME4kj31VAq7c87p3gOcObPdlQFA2xCMI9nVV7e7AgAYcviCSAAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgALBCABAgWAEAKBAMAIAUCAYAQAoEIwAABQGJBhtz7Z9T749Y/vJ4vG4XtZdYvuiJvbx64Gotdjel3Od/HMAAPiTMQOxkYhYI+lVkmT7AkmbI+KLleW2x0TEjjrrLpW0tIl9HD4QteZ6Rkk6RdLjkt4g6aaB2nbVfuo+bwDA0DRovSXbl9q+2Pbtkr5g+1Dbv7F9t+1f2z4wtzvS9nV5+gLbl9i+2fYjts8rtre5aH+z7R/ZfsD292w7Lzs+z1tm+6LKdms4UtIKSV+VdFqxj91t/8T28nw7PM8/0/bv8rzvFs/vnXXq+6XtayXdl+ddk2taYfucYp1jbd+Vt/sL26Ns/8H23Lx8lO2HKo8BAINvQHqMDewt6fCI2Gl7mqTXR8QO22+S9DlJ76ixzkslvVHSVEkP2v5qRLxQ1ebPJC2W9JSkX0n6c9tLJX1N0hERsdL2FQ3qOk3SFZL+WdLnbI/N+7hI0i0RcYrt0ZKm2F4s6eP5eay2PauJ532wpJdHxMr8+H0Rsdb2REl32v6x0j8l3yjqnRURnbYvl3S6pC9LepOk5RGxqnoHOWDPkaQFCxY0URIAoBmDfX7tqojYmaenS7rK9r9JulAp2Gq5PiK2R8RqSc9J2r1Gmzsi4omI6JR0j6QOpUB9pAijmsGYz3keL+maiNgo6XZJx+TFRyn1IhUROyNiQ553Va5HEbG2ied9R1GHJJ1ne7mk30qaL2l/Sa+VdGulXbHdSySdmaffJ+nbtXYQEV+PiCURsWTuXDqUADBQBrvHuKWY/ntJN+XeWIekm+uss72Y3qnaNTbTpp5jJM2QdG8egZ0kaZukesOu9exQ/scin7Ms32T0p+dt+0ilnt9hEbHV9s2SJtTbaEQ8bvtZ20dJOlSp9wgAaJFWviNzuqQn8/RZg7D9ByUtzKErSe+u0+40SR+IiI6I6JC0r6Q3254k6ReSPihJtkfbni7pRknvsj07z68MpT4q6ZA8fZKksXX2N13SuhyKL1XqKUqp93iE7X2rtitJ35R0ubr3uAEALdDKYPyCpP9p+24NQk81IrZJOlfSz2wvk7RJ0oayTQ6/YyVdX6y3RdJtkt4q6XxJb7R9r6RlkhZFxApJn5V0Sx4O/VJe9RuS3pDnHabuvePSzySNsX2/pM8rBaLyecNzJF2dt3Flsc61kqaozjAqAGDwOCLaXcOAsT0lIjbnd6n+o6Q/RMSF7a6rr2wvkXRhRLy+mfZLliyJpUt7/cQLAKBge1lELKmeP9w+3P6Xtu9R+ijGdKV3qe5SbP+1pB9L+pt21wIAI9Gw6jGOVPQYAaDvRkqPEQCAF4VgBACgwFDqMGB7laTH+rn6HEmrB7CcgUJdfUNdfUNdfTNc69onInp8QwrBOMLZXlprjL3dqKtvqKtvqKtvRlpdDKUCAFAgGAEAKBCM+Hq7C6iDuvqGuvqGuvpmRNXFOUYAAAr0GAEAKBCMAAAUCMYRwvaxth+0/VD+Ptbq5eNtX5mX315cvqvddZ1le5Xte/LtAy2o6RLbz+WLatdabtsX5Zp/Z/vgwa6pybqOtL2hOFafbFFd823fZPs+2ytsn1+jTcuPWZN1tfyY2Z5g+w7by3Ndn6rRpuWvxybravnrsdj3aNt32+5x7dwBP14RwW2Y3ySNlvSwpIVKF1RernRJrbLNuZIuztOnSrpyiNR1lqSvtPh4HSHpYEn/Vmf58ZJukGSl62vePkTqOlLSdW34/dpT0sF5eqqk39f4Obb8mDVZV8uPWT4GU/L0WEm3S3ptVZt2vB6bqavlr8di3/9N0vdr/bwG+njRYxwZDpX0UEQ8EhF/lPQDSSdXtTlZ0mV5+keSjs6X72p3XS0XEbdKWtugycmSvhPJbyXNsL3nEKirLSLi6Yi4K09vknS/pHlVzVp+zJqsq+XyMdicH47Nt+p3Qbb89dhkXW1he29JJyhdxL2WAT1eBOPIME/S48XjJ9TzD8Sf2kTEDqWLPM8eAnVJ0jvy8NuPbM8f5Jqa0Wzd7XBYHgq7wfbiVu88D2H9mVJvo9TWY9agLqkNxywPC94j6TlJ/xoRdY9XC1+PzdQltef1+GVJfyWps87yAT1eBCOGuv8rqSMiXinpX9X1XyF6ukvpux8PkvR/JF3Typ3bnqJ0LdEPR8TGVu67kV7qassxi4idEfEqSXtLOtT2y1ux3940UVfLX4+2T5T0XEQsG+x9VRCMI8OTksr/7PbO82q2sT1G6ULPa9pdV0SsiYjt+eE3JR0yyDU1o5nj2XIRsbEyFBYRP5U01vacVuzb9lil8PleRFxdo0lbjllvdbXzmOV9rpd0k6Rjqxa14/XYa11tej3+uaSTbD+qdLrlKNuXV7UZ0ONFMI4Md0ra3/a+tscpnZy+tqrNtZL+Ik+/U9KNkc9kt7OuqvNQJymdJ2q3ayWdmd9p+VpJGyLi6XYXZXuPynkV24cqvb4H/Y9p3ue3JN0fEV+q06zlx6yZutpxzGzPtT0jT0+U9GZJD1Q1a/nrsZm62vF6jIi/iYi9I6JD6W/EjRHx3qpmA3q8xvR3Rew6ImKH7Q9J+n9K7wS9JCJW2P60pKURca3SH5Dv2n5I6Q0epw6Rus6zfZKkHbmuswa7LttXKL1bcY7tJyT9ndIbERQRF0v6qdK7LB+StFXS2YNdU5N1vVPSB23vkLRN0qkt+OdGSv/RnyHp3nx+SpL+VtKCorZ2HLNm6mrHMdtT0mW2RysF8Q8j4rp2vx6brKvlr8d6BvN48ZVwAAAUGEoFAKBAMAIAUCAYAQAoEIwAABQIRgAACgQjAAAFghEAgMK/AyZrZt0Hx3Q8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqL6FYUrtXpf",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "81f2cf78-ea40-4f78-a263-a84defcf4594"
      },
      "source": [
        "# Here's a codeblock just for fun. You should be able to upload an image here \n",
        "# and have it classified without crashing\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(512,512))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e907734f-6dde-43f4-952a-e71dfa6704dc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e907734f-6dde-43f4-952a-e71dfa6704dc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cat-g949f1e28a_1920.jpg to cat-g949f1e28a_1920 (3).jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9b2b15701a32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 246016 values, but the requested shape requires a multiple of 18496\n\t [[node sequential/flatten/Reshape (defined at <ipython-input-21-2f6e5e274805>:19) ]] [Op:__inference_predict_function_15277]\n\nFunction call stack:\npredict_function\n"
          ]
        }
      ]
    }
  ]
}